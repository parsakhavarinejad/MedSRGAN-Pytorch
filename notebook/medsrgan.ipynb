{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\nimport pandas as pd\nimport numpy as np\n\nimport torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2024-07-18T17:13:35.029204Z","iopub.execute_input":"2024-07-18T17:13:35.029690Z","iopub.status.idle":"2024-07-18T17:13:37.449517Z","shell.execute_reply.started":"2024-07-18T17:13:35.029655Z","shell.execute_reply":"2024-07-18T17:13:37.448210Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class RWMAB(nn.Module):\n    \"\"\"\n    This class implements the Residual Whole Map Attention Network (RWMAN),\n    a modification of RCAN for extracting features from low-resolution (LR) images\n    and feeding them into a generator for image upscaling.\n    \"\"\"\n\n    def __init__(self, input_shape: int = 64) -> None:\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(input_shape, 64, kernel_size=3, stride=1),\n            nn.ReLU()\n            nn.Conv2d(64, 64, kernel_size=3, stride=1)\n        )\n        self.attention = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x_out = self.conv1(x)\n        attention = self.attention(x_out)\n        x_out = x * attention + x\n        return x_out\n\nclass ShortResidualConnection(nn.Module):\n    def __init__(self, input_shape: int = 64) -> None:\n        super().__init__()\n        RWMAN = []\n        for _ in range(16):\n            RWMAN.append(RWMAB())\n        \n        self.src = nn.Sequential(*RWMAN, \n                            nn.Conv2d(64, 64, kernel_size=1, stride=1)\n\n        def forward(self, x):\n            x_1 = src(x)\n            return x_1 + x\n            \n            \nclass Generator(nn.Module):\n    \n    def __init__():\n        super().__init__()\n    \n        self.conv_1 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n        self.lrc = []\n        for _ in range(8):\n            self.lrc.append(ShortResidualConnection())\n        self.conv_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n        \n        self.lrc = nn.Sequential(*lrc, conv_2)\n           \n        upsample_1 = nn.Sequential(nn.Conv(64, 256, kernel_size=3, stride=1),\n                                  nn.PixelShuffle(2),\n                                  nn.Conv(256, 256, kernel_size=3, stride=1),\n                                  nn.PixelShuffle(2))\n        conv_3 = nn.Conv2d(256, 1, kernel_size=3, stride=1)\n                            \n        self.upscaler = nn.Sequential(upsample_1, conv_3)\n                            \n    def forward(self, x):\n        x_1 = conv_1(x)   \n        x_2 = lrc(x_1)\n        x_out = x_1 + x_2\n        return upscaler(x_out)                  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DBlock(nn.Module):\n    \n    def __init__(input_shape: int = 64, output_shape: int = 64, stride: int = 2, bn: bool = True) -> None:\n        super().__init__()\n        self.bntrue = bn\n        self.conv_1 = nn.Con2d(input_shape, output_shape, kernel_size=3, stride=stride)\n        self.bn = nn.BatchNorm2d()\n        self.leakyr = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        if self.bntrue:\n            return self.leakyr(self.bn(self.conv_1(x)))\n        else:\n            return self.leakyr(self.conv_1(x))\n\nclass Discriminator(nn.Module):\n    \n    def __init__():\n        super().__init__()\n        self.block_1_sr = nn.Sequential(DBlock(1, 64, 1, False),\n                                DBlock(64, 64, 2))\n        self.block_2_sr = nn.Sequential(DBlock(64, 128, 1),\n                                DBlock(128, 128, 2))\n        self.block_1_lr = nn.Sequential(DBlock(1, 64, 1, False),\n                                DBlock(64, 128, 1, True))\n        \n        self.block_1 = nn.Sequential(DBlock(128, 256, 1),\n                                DBlock(256, 256, 2))\n        self.block_2 = nn.Sequential(DBlock(256, 512, 1),\n                                DBlock(512, 512, 2))\n        self.block_3 = nn.Sequential(DBlock(512, 1024, 1),\n                                DBlock(1024, 1024, 2))\n        \n        self.final = nn.Sequential(nn.Linear(100),\n                                  nn.LeakyReLU(0.2),\n                                  nn.Linear(1),\n                                  nn.Sigmoid())\n        \n    def forward(self, x, y):\n        x_1 = self.block_1_sr(x)\n        x_2 = self.block_2_sr(x_1)\n        \n        y_1 = self.block_1_lr(y)\n        \n        xy = torch.add(x_2, y_1)\n        \n        xy_1 = self.block_1(xy)\n        xy_2 = self.block_1(xy_1)\n        xy_3 = self.block_1(xy_2)\n        \n        final = self.final(xy_3)\n        \n        return (x_1, x_2, xy_1, xy_2, xy_3, final)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeneratorLossFunction(nn.Module):\n    def __init__(self, device: str = 'cuda', lambda1: float = 1e-2, lambda2: float = 1e-4\n                 vgg_layers: list[int] = [2, 7, 16, 25, 34],\n                 weights: list[float] = [1/2, 1/4, 1/8, 1/64, 1/128]) -> None:\n        \n        super().__init__()\n        \n        vgg = models.vgg19(pretrained=True).features.to(device).eval()\n        \n        self.layers = vgg_layers\n        self.weights = weights\n        self.l1_loss = nn.L1Loss()\n        self.mse_loss = nn.MSELoss()\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n\n            \n        for param in self.vgg.parameters():\n            param.requires_grad = False\n\n    def forward(self, discriminator, LR, HR, SR):\n        return content_loss(HR, SR) + self.lambda1 * adverserial_loss(discriminator, LR, HR, SR) + self.lambda2 * adverserial_feature_loss(discriminator, LR, HR, SR)\n\n    def vgg_extract(self, x):\n        features = []\n        for layer in layers:\n            features.append(vgg19.features[layer](x))\n            \n        return features\n    \n    def content_loss(self, HR, SR, lambda_l1=0):\n        \n        HR_features = self.vgg_extract(HR)\n        SR_features = self.vgg_extract(SR)\n        \n        loss = 0.0\n        for i in range(len(self.layers)):\n            loss += self.weights[i] * self.mse_loss(SR_features[i], HR_features[i])\n        \n        l1_loss = self.l1_loss(HR, SR)\n        content_loss = lambda_l1 * l1_loss + loss\n        \n        return content_loss\n        \n        \n    def adversarial_loss(discriminator, lr, hr, sr):\n        \"\"\"\n        Compute the adversarial loss for the generator.\n        \"\"\"\n        d_real = discriminator(lr, hr)[-1]\n        d_fake = discriminator(lr, sr)[-1]\n        adv = -torch.log(1 - d_real) - torch.log(d_fake)\n        return adv.mean()\n        \n    def adversarial_feature_loss(discriminator, lr, hr, sr):\n        \"\"\"\n        Compute the adversarial feature loss for the generator.\n        \"\"\"\n\n        weights = [1/2, 1/4, 1/8, 1/64, 1/128]\n\n        d_real = discriminator(lr, hr)\n        d_fake = discriminator(lr, sr)\n\n        advfeat = 0\n        for idx in range(len(weights)):\n            advfeat += weights[idx] *  nn.MSELoss()(d_real[idx], d_fake[idx])\n\n        return advfeat.mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiscriminatorLossFunction(nn.Module):\n    def __init__(self, device: str = 'cuda', discriminator)\n        super().__init__()\n        self.d = discriminator\n        \n    def forward(lr, hr, sr):\n        loss = -1*torch.log(self.d(lr, hr)) - torch.log(1-self.d(lr, sr))\n        return loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer(nn.Module):\n    \n    def __init__(self, generator: nn.Module = None, discriminator: nn.Module = None,\n                 g_loss = nn.Module = None, d_loss: nn.Module = None,\n                 batch_size: int = 4, dataloader: torch.Dataloader = None,\n                 mean: tuple(float, float, float) = (0.5, 0.5, 0.5),\n                 std: tuple(float, float, float) = (0.5, 0.5, 0.5),\n                 device: str = 'cuda') -> None:\n        super().__init__()\n        \n        self.generator = generator\n        self.discriminator = discriminator\n        self.dataloader = dataloader\n        self.mean = mean\n        self.fixed_latent = torch.randn(batch_size, 512, 14, 14)\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.device = device\n        \n    def denorm(self, img_tensor: torch.Tensor) -> torch.Tensor:\n        return img_tensor * self.mean[0] + self.std[0]\n    \n     def save_samples(self, index: int = 0) -> None:\n            \n        latent_tensors = torch.randn(64, self.latent_size, 1, 1, device=self.device)\n        fake_images = self.generator(latent_tensors)\n        fake_fname = f'generated-images-{index:04d}.png'\n        save_image(fake_images, os.path.join(fake_fname), nrow=8)\n        print('Saving', fake_fname)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(self.denorm(fake_images.cpu().detach()), nrow=8).permute(1, 2, 0))\n        plt.show()\n        \n    def train_discriminator(self, real_images, opt_d):\n        opt_d.zero_grad()\n\n        real_preds = self.discriminator(real_images)[-1]\n        real_targets = torch.ones(real_images.size(0), 1, device=self.device)\n        real_loss = F.binary_cross_entropy(real_preds, real_targets)\n        \n        real_score = torch.mean(real_preds).item()\n\n        latent = torch.randn(real_images.size(0), self.latent_size, 1, 1, device=self.device)\n        fake_images = self.generator(latent)\n\n        fake_targets = torch.zeros(real_images.size(0), 1, device=self.device)\n        fake_preds = self.discriminator(fake_images.detach())\n        fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n        fake_score = torch.mean(fake_preds).item()\n\n        loss = real_loss + fake_loss\n        loss.backward()\n        opt_d.step()\n\n        return loss.item(), real_score, fake_score\n\n    def train_generator(self, opt_g):\n        opt_g.zero_grad()\n\n        latent = torch.randn(self.train_dl.batch_size, self.latent_size, 1, 1, device=self.device)\n        fake_images = self.generator(latent)\n\n        preds = self.discriminator(fake_images)\n        targets = torch.ones(self.train_dl.batch_size, 1, device=self.device)\n        loss = F.binary_cross_entropy(preds, targets)\n\n        loss.backward()\n        opt_g.step()\n\n        return loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:18:26.492741Z","iopub.execute_input":"2024-07-25T14:18:26.493410Z","iopub.status.idle":"2024-07-25T14:18:26.530734Z","shell.execute_reply.started":"2024-07-25T14:18:26.493374Z","shell.execute_reply":"2024-07-25T14:18:26.529281Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    dataloader: torch.Dataloader, mean: tuple(float, float, float) = (0.5, 0.5, 0.5),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"],"ename":"SyntaxError","evalue":"non-default argument follows default argument (3728780873.py, line 4)","output_type":"error"}]},{"cell_type":"code","source":"generator = Generator().to('cuda')\ndiscriminator = Discriminator().to('cuda')\n\ngen_loss = GeneratorLoss()\ndisc_loss = DescriminatorLoss()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}