{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8364728,"sourceType":"datasetVersion","datasetId":4971917}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.datasets as torch_data\nimport torch.nn.functional as F\n\nfrom PIL import Image\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:34:28.641164Z","iopub.execute_input":"2024-08-16T14:34:28.641860Z","iopub.status.idle":"2024-08-16T14:34:34.446359Z","shell.execute_reply.started":"2024-08-16T14:34:28.641824Z","shell.execute_reply":"2024-08-16T14:34:34.445546Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import glob\n\nall_data = glob.glob('/kaggle/input/echo-all/Extracted/*.jpg')\ndata = [path for path in all_data if '_mask' not in path]\n\ndataframe = pd.DataFrame(data, columns=['paths'])","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:34:34.447966Z","iopub.execute_input":"2024-08-16T14:34:34.448595Z","iopub.status.idle":"2024-08-16T14:34:34.746532Z","shell.execute_reply.started":"2024-08-16T14:34:34.448566Z","shell.execute_reply":"2024-08-16T14:34:34.745548Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(self, dataframe: list, lr_transforms, hr_transforms):\n        self.data = dataframe\n        self.lr_transforms = lr_transforms\n        self.hr_transforms = hr_transforms\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path = self.data.iloc[idx]['paths']\n\n        hr_images = Image.open(image_path).convert('L') \n\n        lr_image = self.lr_transforms(hr_images)\n        hr_image = self.hr_transforms(hr_images)\n\n        return lr_image, hr_image","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:34:47.312352Z","iopub.execute_input":"2024-08-16T14:34:47.312717Z","iopub.status.idle":"2024-08-16T14:34:47.319484Z","shell.execute_reply.started":"2024-08-16T14:34:47.312676Z","shell.execute_reply":"2024-08-16T14:34:47.318570Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class InterpolateTransform:\n    def __init__(self, size, mode='bicubic'):\n        self.size = size\n        self.mode = mode\n    \n    def __call__(self, tensor):\n        return F.interpolate(tensor.unsqueeze(0), size=self.size, mode=self.mode, align_corners=False).squeeze(0)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:34:48.206647Z","iopub.execute_input":"2024-08-16T14:34:48.207284Z","iopub.status.idle":"2024-08-16T14:34:48.212562Z","shell.execute_reply.started":"2024-08-16T14:34:48.207245Z","shell.execute_reply":"2024-08-16T14:34:48.211530Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_size = 256\n   \n    \nhr_transforms = transforms.Compose([\n    transforms.Resize([image_size, image_size]),\n    transforms.ToTensor(),\n])\n\n\nlr_transforms = transforms.Compose([\n    transforms.Resize([image_size, image_size]),\n    transforms.ToTensor(),\n    InterpolateTransform(size=(image_size // 4, image_size // 4)),\n])\n\ntrain_dataset = CustomDataset(dataframe, lr_transforms, hr_transforms)\n\nbatch_size = 1\ndataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:47:32.092758Z","iopub.execute_input":"2024-08-16T14:47:32.093372Z","iopub.status.idle":"2024-08-16T14:47:32.099777Z","shell.execute_reply.started":"2024-08-16T14:47:32.093341Z","shell.execute_reply":"2024-08-16T14:47:32.098745Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"for batch in dataloader:\n    inputs = batch\n    print(\"Input shape:\", inputs[0].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:47:32.457126Z","iopub.execute_input":"2024-08-16T14:47:32.457498Z","iopub.status.idle":"2024-08-16T14:47:32.474437Z","shell.execute_reply.started":"2024-08-16T14:47:32.457468Z","shell.execute_reply":"2024-08-16T14:47:32.473531Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Input shape: torch.Size([1, 1, 64, 64])\n","output_type":"stream"}]},{"cell_type":"code","source":"print('LR shape: ', inputs[0][3].shape)\nplt.imshow(inputs[0][3].permute(1,2,0).numpy())\nplt.show()\nprint('HR shape: ', inputs[1][3].shape)\nplt.imshow(inputs[1][3].permute(1,2,0).numpy())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:47:32.762221Z","iopub.execute_input":"2024-08-16T14:47:32.762853Z","iopub.status.idle":"2024-08-16T14:47:32.800640Z","shell.execute_reply.started":"2024-08-16T14:47:32.762822Z","shell.execute_reply":"2024-08-16T14:47:32.799370Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(inputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 1"],"ename":"IndexError","evalue":"index 3 is out of bounds for dimension 0 with size 1","output_type":"error"}]},{"cell_type":"code","source":"class RWMAB(nn.Module):\n    \"\"\"\n    This class implements the Residual Whole Map Attention Network (RWMAN),\n    a modification of RCAN for extracting features from low-resolution (LR) images\n    and feeding them into a generator for image upscaling.\n    \"\"\"\n\n    def __init__(self, input_shape: int = 64) -> None:\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(input_shape, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n        )\n        self.attention = nn.Sequential(\n            nn.Conv2d(64, 64, kernel_size=1, stride=1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        x_out = self.conv1(x)\n        attention = self.attention(x_out)\n        x_out = torch.mul(x_out, attention) + x\n        return x_out\n\nclass ShortResidualConnection(nn.Module):\n    def __init__(self, input_shape: int = 64) -> None:\n        super().__init__()\n        RWMAN = []\n        for _ in range(16):\n            RWMAN.append(RWMAB())\n        \n        self.src = nn.Sequential(*RWMAN, \n                            nn.Conv2d(64, 64, kernel_size=1, stride=1))\n\n    def forward(self, x):\n        x_1 = self.src(x)\n        return x_1 + x\n\n\nclass Generator(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n    \n        self.conv_1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n        self.lrc = []\n        for _ in range(8):\n            self.lrc.append(ShortResidualConnection())\n        self.conv_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.lrc = nn.Sequential(*self.lrc, self.conv_2)\n        \n        upsample_1 = nn.Sequential(nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n                                  nn.PixelShuffle(2),\n                                  nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n                                  nn.PixelShuffle(2))\n        conv_3 = nn.Conv2d(64, 1, kernel_size=3, stride=1)\n                            \n        self.upscaler = nn.Sequential(upsample_1, conv_3)\n                            \n    def forward(self, x):\n        x_1 = self.conv_1(x)   \n        x_2 = self.lrc(x_1)\n        x_out = x_1 + x_2\n        return self.upscaler(x_out)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:47:32.998222Z","iopub.execute_input":"2024-08-16T14:47:32.999041Z","iopub.status.idle":"2024-08-16T14:47:33.013976Z","shell.execute_reply.started":"2024-08-16T14:47:32.999007Z","shell.execute_reply":"2024-08-16T14:47:33.013061Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class DBlock(nn.Module):\n    \n    def __init__(self, input_shape: int = 64,\n                 output_shape: int = 64,\n                 stride: int = 2,\n                 bn: bool = True,\n                 padding: int = 1) -> None:\n        super().__init__()\n        self.bntrue = bn\n        self.conv_1 = nn.Conv2d(input_shape, output_shape, kernel_size=3, stride=stride, padding=padding)\n        self.bn = nn.BatchNorm2d(num_features=output_shape)\n        self.leakyr = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        if self.bn == True:\n            return self.leakyr(self.bn(self.conv_1(x)))\n        else:\n            return self.leakyr(self.conv_1(x))\n\nclass Discriminator(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        self.block_1_sr = nn.Sequential(DBlock(1, 64, stride=1, bn=False),\n                                DBlock(64, 64, stride=2))\n        self.block_2_sr = nn.Sequential(DBlock(64, 128, stride=1),\n                                DBlock(128, 128, stride=2))\n        self.block_1_lr = nn.Sequential(DBlock(1, 64, stride=1, bn=False),\n                                DBlock(64, 128, stride=1, bn=True))\n        \n        self.block_1 = nn.Sequential(DBlock(128, 256, stride=1),\n                                DBlock(256, 256, stride=2))\n        self.block_2 = nn.Sequential(DBlock(256, 512, stride=1),\n                                DBlock(512, 512, stride=2))\n        self.block_3 = nn.Sequential(DBlock(512, 1024, stride=1),\n                                DBlock(1024, 1024, stride=2))\n        \n        self.final = nn.Sequential(nn.Linear(1024*8*8,100),\n                                  nn.LeakyReLU(0.2),\n                                  nn.Linear(100, 1),\n                                  nn.Sigmoid())\n        \n    def forward(self, y, x):\n        x_1 = self.block_1_sr(x)\n        x_2 = self.block_2_sr(x_1)\n        y_1 = self.block_1_lr(y)\n        xy = torch.add(x_2, y_1)\n        xy_1 = self.block_1(xy)\n        xy_2 = self.block_2(xy_1)\n        xy_3 = self.block_3(xy_2)\n        xy_3 = xy_3.view(xy_3.size(0), -1)\n        final = self.final(xy_3)\n        \n        return (x_1, x_2, xy_1, xy_2, xy_3, final)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:47:33.225409Z","iopub.execute_input":"2024-08-16T14:47:33.225797Z","iopub.status.idle":"2024-08-16T14:47:33.240670Z","shell.execute_reply.started":"2024-08-16T14:47:33.225766Z","shell.execute_reply":"2024-08-16T14:47:33.239554Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class GeneratorLossFunction(nn.Module):\n    def __init__(self, device: str = 'cuda', lambda1: float = 1e-2, lambda2: float = 1e-4,\n                 vgg_layers: list[int] = [2, 7, 16, 25, 34],\n                 weights: list[float] = [1/2, 1/4, 1/8, 1/64, 1/128]) -> None:\n        \n        super().__init__()\n        \n        self.vgg = models.vgg19(pretrained=True).features.to(device).eval()\n        \n        self.layers = vgg_layers\n        self.weights = weights\n        self.l1_loss = nn.L1Loss()\n        self.mse_loss = nn.MSELoss()\n        self.lambda1 = lambda1\n        self.lambda2 = lambda2\n\n            \n        for param in self.vgg.parameters():\n            param.requires_grad = False\n\n    def forward(self, discriminator, LR, HR, SR):\n        return self.content_loss(HR, SR) + self.lambda1 * self.adverserial_loss(discriminator, LR, HR, SR) + self.lambda2 * self.adverserial_feature_loss(discriminator, LR, HR, SR)\n\n    def vgg_extract(self, x):\n        features = []\n        for layer in self.layers:\n            features.append(self.vgg.features[layer](x))\n            \n        return features\n    \n    def content_loss(self, HR, SR, lambda_l1=0):\n        \n        HR_features = self.vgg_extract(HR)\n        SR_features = self.vgg_extract(SR)\n        \n        loss = 0.0\n        for i in range(len(self.layers)):\n            loss += self.weights[i] * self.mse_loss(SR_features[i], HR_features[i])\n        \n        l1_loss = self.l1_loss(HR, SR)\n        content_loss = lambda_l1 * l1_loss + loss\n        \n        return content_loss\n        \n        \n    def adversarial_loss(discriminator, lr, hr, sr):\n        \"\"\"\n        Compute the adversarial loss for the generator.\n        \"\"\"\n        d_real = discriminator(lr, hr)[-1]\n        d_fake = discriminator(lr, sr)[-1]\n        adv = -torch.log(1 - d_real) - torch.log(d_fake)\n        return adv.mean()\n        \n    def adversarial_feature_loss(discriminator, lr, hr, sr):\n        \"\"\"\n        Compute the adversarial feature loss for the generator.\n        \"\"\"\n\n        weights = [1/2, 1/4, 1/8, 1/64, 1/128]\n\n        d_real = discriminator(lr, hr)\n        d_fake = discriminator(lr, sr)\n\n        advfeat = 0\n        for idx in range(len(weights)):\n            advfeat += weights[idx] *  nn.MSELoss()(d_real[idx], d_fake[idx])\n\n        return advfeat.mean()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:34.579249Z","iopub.execute_input":"2024-08-16T14:52:34.579623Z","iopub.status.idle":"2024-08-16T14:52:34.595512Z","shell.execute_reply.started":"2024-08-16T14:52:34.579594Z","shell.execute_reply":"2024-08-16T14:52:34.594591Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"class DiscriminatorLossFunction(nn.Module):\n    def __init__(self, device: str = 'cuda'):\n        super().__init__()\n        \n    def forward(lr, hr, sr):\n        loss = -1*torch.log(hr) - torch.log(1-sr)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:35.063291Z","iopub.execute_input":"2024-08-16T14:52:35.064171Z","iopub.status.idle":"2024-08-16T14:52:35.069254Z","shell.execute_reply.started":"2024-08-16T14:52:35.064135Z","shell.execute_reply":"2024-08-16T14:52:35.068403Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"class Trainer(nn.Module):\n    \n    def __init__(self, generator: nn.Module = None, discriminator: nn.Module = None,\n                 g_loss: nn.Module = None, d_loss: nn.Module = None,\n                 batch_size: int = 4, dataloader: DataLoader = None,\n                 mean: tuple[float, float, float] = (0.5, 0.5, 0.5),\n                 std: tuple[float, float, float] = (0.5, 0.5, 0.5),\n                 device: str = 'cuda') -> None:\n        super().__init__()\n        \n        self.generator = generator\n        self.discriminator = discriminator\n        self.dataloader = dataloader\n        self.mean = mean\n        self.fixed_latent = torch.randn(batch_size, 512, 14, 14)\n        self.g_loss = g_loss\n        self.d_loss = d_loss\n        self.device = device\n        \n    def denorm(self, img_tensor: torch.Tensor) -> torch.Tensor:\n        return img_tensor * self.mean[0] + self.std[0]\n    \n    def save_samples(self, index: int = 0) -> None:\n            \n        latent_tensors = torch.randn(64, self.latent_size, 1, 1, device=self.device)\n        fake_images = self.generator(latent_tensors)\n        fake_fname = f'generated-images-{index:04d}.png'\n        save_image(fake_images, os.path.join(fake_fname), nrow=8)\n        print('Saving', fake_fname)\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(self.denorm(fake_images.cpu().detach()), nrow=8).permute(1, 2, 0))\n        plt.show()\n        \n    def train_discriminator(self, lr_image, hr_image, opt_d):\n        opt_d.zero_grad()\n\n        hr_preds = self.discriminator(lr_image, hr_image)[-1]\n        hr_targets = torch.ones(lr_image.size(0), 1, device=self.device)\n        real_loss = F.binary_cross_entropy(hr_preds, hr_targets)\n        real_score = torch.mean(hr_preds).item()\n        \n        sr_image = self.generator(lr_image)\n        sr_targets = torch.zeros(lr_image.size(0), 1, device=self.device)\n        sr_preds = self.discriminator(lr_image, sr_image)[-1]\n        fake_loss = F.binary_cross_entropy(sr_preds, sr_targets)\n        fake_score = torch.mean(sr_preds).item()\n\n        loss = real_loss + fake_loss\n        loss.backward()\n        opt_d.step()\n\n        return loss.item(), real_score, fake_score\n\n    def train_generator(self, lr_image, hr_image, opt_g):\n        opt_g.zero_grad()\n        \n        sr_image = self.generator(lr_image)\n\n        preds = self.discriminator(lr_image, sr_image)[-1]\n        targets = torch.ones(lr_image.size(0), 1, device=self.device)\n        loss = self.g_loss(self.discriminator, lr_image, hr_image, sr_image)\n\n        loss.backward()\n        opt_g.step()\n\n        return loss.item()\n    \n    \n    def fit(self, epochs: int = 100, learning_rate: float = 1e-4, beta: tuple[float, float] = (0.9, 0.999), start_idx=1):\n        torch.cuda.empty_cache()\n\n        losses_g = []\n        losses_d = []\n        real_scores = []\n        fake_scores = []\n\n        opt_d = optim.Adam(self.discriminator.parameters(), lr=learning_rate, betas=beta)\n        opt_g = optim.Adam(self.generator.parameters(), lr=learning_rate, betas=beta)\n\n        for epoch in range(epochs):\n            for real_images in tqdm.tqdm(self.dataloader):\n                lr_image, hr_image = real_images[0].to(self.device), real_images[1].to(self.device)\n                loss_d, real_score, fake_score = self.train_discriminator(lr_image, hr_image, opt_d)\n                loss_g = self.train_generator(lr_image, hr_image, opt_g)\n\n            losses_g.append(loss_g)\n            losses_d.append(loss_d)\n            real_scores.append(real_score)\n            fake_scores.append(fake_score)\n\n            print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n                epoch + 1, epochs, loss_g, loss_d, real_score, fake_score))\n            \n            if epoch % 10 == 0:\n                # Save generated images\n                self.save_samples(epoch + start_idx)\n\n        return losses_g, losses_d, real_scores, fake_scores","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:35.278463Z","iopub.execute_input":"2024-08-16T14:52:35.278857Z","iopub.status.idle":"2024-08-16T14:52:35.302043Z","shell.execute_reply.started":"2024-08-16T14:52:35.278826Z","shell.execute_reply":"2024-08-16T14:52:35.301013Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"generator = Generator().to('cuda')\ndiscriminator = Discriminator().to('cuda')\n\ngen_loss = GeneratorLossFunction()\ndis_loss = DiscriminatorLossFunction()\n\ntrainer = Trainer(generator, discriminator, gen_loss, dis_loss, dataloader=dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:35.457078Z","iopub.execute_input":"2024-08-16T14:52:35.457455Z","iopub.status.idle":"2024-08-16T14:52:37.231457Z","shell.execute_reply.started":"2024-08-16T14:52:35.457425Z","shell.execute_reply":"2024-08-16T14:52:37.230472Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"losses_g, losses_d, real_scores, fake_scores = trainer.fit()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:37.233148Z","iopub.execute_input":"2024-08-16T14:52:37.233443Z","iopub.status.idle":"2024-08-16T14:52:37.666410Z","shell.execute_reply.started":"2024-08-16T14:52:37.233419Z","shell.execute_reply":"2024-08-16T14:52:37.664950Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"  0%|          | 0/6293 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses_g, losses_d, real_scores, fake_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[66], line 85\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, epochs, learning_rate, beta, start_idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m     lr_image, hr_image \u001b[38;5;241m=\u001b[39m real_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), real_images[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     84\u001b[0m     loss_d, real_score, fake_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_discriminator(lr_image, hr_image, opt_d)\n\u001b[0;32m---> 85\u001b[0m     loss_g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_g\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m losses_g\u001b[38;5;241m.\u001b[39mappend(loss_g)\n\u001b[1;32m     88\u001b[0m losses_d\u001b[38;5;241m.\u001b[39mappend(loss_d)\n","Cell \u001b[0;32mIn[66], line 62\u001b[0m, in \u001b[0;36mTrainer.train_generator\u001b[0;34m(self, lr_image, hr_image, opt_g)\u001b[0m\n\u001b[1;32m     60\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator(lr_image, sr_image)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     61\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(lr_image\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 62\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     65\u001b[0m opt_g\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[64], line 22\u001b[0m, in \u001b[0;36mGeneratorLossFunction.forward\u001b[0;34m(self, discriminator, LR, HR, SR)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, discriminator, LR, HR, SR):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSR\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madverserial_loss(discriminator, LR, HR, SR) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madverserial_feature_loss(discriminator, LR, HR, SR)\n","Cell \u001b[0;32mIn[64], line 33\u001b[0m, in \u001b[0;36mGeneratorLossFunction.content_loss\u001b[0;34m(self, HR, SR, lambda_l1)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontent_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, HR, SR, lambda_l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     HR_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     SR_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvgg_extract(SR)\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n","Cell \u001b[0;32mIn[64], line 27\u001b[0m, in \u001b[0;36mGeneratorLossFunction.vgg_extract\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 27\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m[layer](x))\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'features'"],"ename":"AttributeError","evalue":"'Sequential' object has no attribute 'features'","output_type":"error"}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-08-16T14:52:37.667273Z","iopub.status.idle":"2024-08-16T14:52:37.667760Z","shell.execute_reply.started":"2024-08-16T14:52:37.667509Z","shell.execute_reply":"2024-08-16T14:52:37.667529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}